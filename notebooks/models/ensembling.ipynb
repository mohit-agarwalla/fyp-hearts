{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import utils\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['AttNet+Baseline+lead1', 'ResNet+Baseline+lead1', \n",
    "          'VGGNet+lead1', 'AlexNet+lead1', 'LeNet+lead1']\n",
    "modelnames = ['AttNet', 'ResNet', 'VGGNet', 'AlexNet', 'LeNet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = []\n",
    "\n",
    "for model in models:\n",
    "    file = f\"C://Mohit/Imperial/fyp-hearts/output/exp4/models/{model}/y_test_pred.npy\"\n",
    "    y_pred = np.load(file, allow_pickle=True)\n",
    "    y_test_preds += [y_pred]\n",
    "\n",
    "y_test = np.load(f\"C://Mohit/Imperial/fyp-hearts/output/exp4/data/y_test.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.862222910532775"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_preds = np.array(y_test_preds).mean(axis=0)\n",
    "\n",
    "roc_auc_score(y_test, mean_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trimmed SMV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.862222910532775"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data = np.sort(np.array(y_test_preds), axis=0)\n",
    "trimmed_data = sorted_data[1:-1, :, :]\n",
    "trim_preds = sorted_data.mean(axis=0)\n",
    "roc_auc_score(y_test, trim_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## weighted smv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds = []\n",
    "\n",
    "for model in models:\n",
    "    file = f\"C://Mohit/Imperial/fyp-hearts/output/exp4/models/{model}/y_val_pred.npy\"\n",
    "    y_pred = np.load(file, allow_pickle=True)\n",
    "    y_val_preds += [y_pred]\n",
    "\n",
    "y_val = np.load(f\"C://Mohit/Imperial/fyp-hearts/output/exp4/data/y_val.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds =np.array(y_val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "methods = models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Mohit\\Imperial\\fyp-hearts\\output\\exp4\\data\\mlb.pkl\", 'rb') as f:\n",
    "    mlb = pickle.load(f).classes_\n",
    "y_test =np.load(r\"C:\\Mohit\\Imperial\\fyp-hearts\\output\\exp4\\data\\y_test.npy\", allow_pickle=True)\n",
    "y_val =np.load(r\"C:\\Mohit\\Imperial\\fyp-hearts\\output\\exp4\\data\\y_val.npy\", allow_pickle=True)\n",
    "\n",
    "val_aucs = pd.DataFrame(columns=methods, index=mlb)\n",
    "\n",
    "for index in range(43):\n",
    "    true = y_val[:,index]\n",
    "    for method in range(len(methods)):\n",
    "        pred = y_val_preds[method][:,index]\n",
    "        val_aucs[methods[method]][mlb[index]] = roc_auc_score(true, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AttNet+Baseline+lead1</th>\n",
       "      <th>ResNet+Baseline+lead1</th>\n",
       "      <th>VGGNet+lead1</th>\n",
       "      <th>AlexNet+lead1</th>\n",
       "      <th>LeNet+lead1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2AVB</th>\n",
       "      <td>0.943768</td>\n",
       "      <td>0.942362</td>\n",
       "      <td>0.945173</td>\n",
       "      <td>0.947985</td>\n",
       "      <td>0.761949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3AVB</th>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.996718</td>\n",
       "      <td>0.907642</td>\n",
       "      <td>0.911158</td>\n",
       "      <td>0.966479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABQRS</th>\n",
       "      <td>0.619343</td>\n",
       "      <td>0.619621</td>\n",
       "      <td>0.585254</td>\n",
       "      <td>0.611522</td>\n",
       "      <td>0.62649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFIB</th>\n",
       "      <td>0.985981</td>\n",
       "      <td>0.981504</td>\n",
       "      <td>0.965162</td>\n",
       "      <td>0.975599</td>\n",
       "      <td>0.924495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFLT</th>\n",
       "      <td>0.970193</td>\n",
       "      <td>0.998724</td>\n",
       "      <td>0.991139</td>\n",
       "      <td>0.985164</td>\n",
       "      <td>0.947033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALMI</th>\n",
       "      <td>0.944395</td>\n",
       "      <td>0.932459</td>\n",
       "      <td>0.824623</td>\n",
       "      <td>0.890264</td>\n",
       "      <td>0.894505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMI</th>\n",
       "      <td>0.64139</td>\n",
       "      <td>0.652745</td>\n",
       "      <td>0.645387</td>\n",
       "      <td>0.630181</td>\n",
       "      <td>0.68878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASMI</th>\n",
       "      <td>0.849539</td>\n",
       "      <td>0.866553</td>\n",
       "      <td>0.823071</td>\n",
       "      <td>0.849554</td>\n",
       "      <td>0.849892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLBBB</th>\n",
       "      <td>0.977486</td>\n",
       "      <td>0.986349</td>\n",
       "      <td>0.972556</td>\n",
       "      <td>0.99038</td>\n",
       "      <td>0.988903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRBBB</th>\n",
       "      <td>0.994187</td>\n",
       "      <td>0.991337</td>\n",
       "      <td>0.963448</td>\n",
       "      <td>0.988488</td>\n",
       "      <td>0.982998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EL</th>\n",
       "      <td>0.819012</td>\n",
       "      <td>0.869271</td>\n",
       "      <td>0.797741</td>\n",
       "      <td>0.858447</td>\n",
       "      <td>0.815153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ILMI</th>\n",
       "      <td>0.745516</td>\n",
       "      <td>0.797556</td>\n",
       "      <td>0.7237</td>\n",
       "      <td>0.759334</td>\n",
       "      <td>0.70708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMI</th>\n",
       "      <td>0.714227</td>\n",
       "      <td>0.685399</td>\n",
       "      <td>0.689993</td>\n",
       "      <td>0.70193</td>\n",
       "      <td>0.694948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INJAL</th>\n",
       "      <td>0.835031</td>\n",
       "      <td>0.874465</td>\n",
       "      <td>0.877358</td>\n",
       "      <td>0.856101</td>\n",
       "      <td>0.804245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INJAS</th>\n",
       "      <td>0.898838</td>\n",
       "      <td>0.924629</td>\n",
       "      <td>0.914403</td>\n",
       "      <td>0.877844</td>\n",
       "      <td>0.843943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INJIL</th>\n",
       "      <td>0.856774</td>\n",
       "      <td>0.898265</td>\n",
       "      <td>0.805204</td>\n",
       "      <td>0.875996</td>\n",
       "      <td>0.812471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INJIN</th>\n",
       "      <td>0.748945</td>\n",
       "      <td>0.858181</td>\n",
       "      <td>0.6376</td>\n",
       "      <td>0.702063</td>\n",
       "      <td>0.712846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INJLA</th>\n",
       "      <td>0.975387</td>\n",
       "      <td>0.940928</td>\n",
       "      <td>0.885373</td>\n",
       "      <td>0.975856</td>\n",
       "      <td>0.957571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IPLMI</th>\n",
       "      <td>0.942347</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90507</td>\n",
       "      <td>0.953427</td>\n",
       "      <td>0.787512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IPMI</th>\n",
       "      <td>0.8374</td>\n",
       "      <td>0.915885</td>\n",
       "      <td>0.828602</td>\n",
       "      <td>0.814641</td>\n",
       "      <td>0.836227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISCAL</th>\n",
       "      <td>0.911698</td>\n",
       "      <td>0.927538</td>\n",
       "      <td>0.899666</td>\n",
       "      <td>0.903335</td>\n",
       "      <td>0.882113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISCAN</th>\n",
       "      <td>0.856338</td>\n",
       "      <td>0.904601</td>\n",
       "      <td>0.884319</td>\n",
       "      <td>0.883944</td>\n",
       "      <td>0.821596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISCAS</th>\n",
       "      <td>0.843387</td>\n",
       "      <td>0.821252</td>\n",
       "      <td>0.778773</td>\n",
       "      <td>0.769288</td>\n",
       "      <td>0.737322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISCIL</th>\n",
       "      <td>0.784968</td>\n",
       "      <td>0.826746</td>\n",
       "      <td>0.77064</td>\n",
       "      <td>0.803207</td>\n",
       "      <td>0.827665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISCIN</th>\n",
       "      <td>0.623035</td>\n",
       "      <td>0.643173</td>\n",
       "      <td>0.619836</td>\n",
       "      <td>0.629781</td>\n",
       "      <td>0.614723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISCLA</th>\n",
       "      <td>0.792046</td>\n",
       "      <td>0.795245</td>\n",
       "      <td>0.760726</td>\n",
       "      <td>0.806796</td>\n",
       "      <td>0.657675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISC_</th>\n",
       "      <td>0.926782</td>\n",
       "      <td>0.918452</td>\n",
       "      <td>0.897914</td>\n",
       "      <td>0.916939</td>\n",
       "      <td>0.919546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LMI</th>\n",
       "      <td>0.783191</td>\n",
       "      <td>0.858156</td>\n",
       "      <td>0.628534</td>\n",
       "      <td>0.752222</td>\n",
       "      <td>0.813995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LNGQT</th>\n",
       "      <td>0.814885</td>\n",
       "      <td>0.808172</td>\n",
       "      <td>0.792393</td>\n",
       "      <td>0.836395</td>\n",
       "      <td>0.672358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDT</th>\n",
       "      <td>0.817373</td>\n",
       "      <td>0.832816</td>\n",
       "      <td>0.788476</td>\n",
       "      <td>0.839092</td>\n",
       "      <td>0.809816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NORM</th>\n",
       "      <td>0.887459</td>\n",
       "      <td>0.882658</td>\n",
       "      <td>0.886405</td>\n",
       "      <td>0.889189</td>\n",
       "      <td>0.867682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NST_</th>\n",
       "      <td>0.780259</td>\n",
       "      <td>0.825528</td>\n",
       "      <td>0.774259</td>\n",
       "      <td>0.781023</td>\n",
       "      <td>0.781696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAC</th>\n",
       "      <td>0.913544</td>\n",
       "      <td>0.71111</td>\n",
       "      <td>0.76963</td>\n",
       "      <td>0.870036</td>\n",
       "      <td>0.650358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PMI</th>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.994609</td>\n",
       "      <td>0.519925</td>\n",
       "      <td>0.853258</td>\n",
       "      <td>0.759025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSVT</th>\n",
       "      <td>0.988118</td>\n",
       "      <td>0.997498</td>\n",
       "      <td>0.994059</td>\n",
       "      <td>0.996873</td>\n",
       "      <td>0.992495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PVC</th>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.93351</td>\n",
       "      <td>0.943566</td>\n",
       "      <td>0.960474</td>\n",
       "      <td>0.844193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SBRAD</th>\n",
       "      <td>0.950982</td>\n",
       "      <td>0.961379</td>\n",
       "      <td>0.929804</td>\n",
       "      <td>0.929887</td>\n",
       "      <td>0.934263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR</th>\n",
       "      <td>0.92252</td>\n",
       "      <td>0.859408</td>\n",
       "      <td>0.895632</td>\n",
       "      <td>0.910912</td>\n",
       "      <td>0.819938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD_</th>\n",
       "      <td>0.825511</td>\n",
       "      <td>0.847961</td>\n",
       "      <td>0.809211</td>\n",
       "      <td>0.843205</td>\n",
       "      <td>0.843726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STE_</th>\n",
       "      <td>0.551282</td>\n",
       "      <td>0.598812</td>\n",
       "      <td>0.542996</td>\n",
       "      <td>0.511413</td>\n",
       "      <td>0.51157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVTAC</th>\n",
       "      <td>0.9606</td>\n",
       "      <td>0.973108</td>\n",
       "      <td>0.987805</td>\n",
       "      <td>0.988743</td>\n",
       "      <td>0.993277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAB_</th>\n",
       "      <td>0.686063</td>\n",
       "      <td>0.810183</td>\n",
       "      <td>0.815462</td>\n",
       "      <td>0.824261</td>\n",
       "      <td>0.897349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WPW</th>\n",
       "      <td>0.686829</td>\n",
       "      <td>0.820354</td>\n",
       "      <td>0.7692</td>\n",
       "      <td>0.809815</td>\n",
       "      <td>0.692535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AttNet+Baseline+lead1 ResNet+Baseline+lead1 VGGNet+lead1 AlexNet+lead1  \\\n",
       "2AVB               0.943768              0.942362     0.945173      0.947985   \n",
       "3AVB               0.974684              0.996718     0.907642      0.911158   \n",
       "ABQRS              0.619343              0.619621     0.585254      0.611522   \n",
       "AFIB               0.985981              0.981504     0.965162      0.975599   \n",
       "AFLT               0.970193              0.998724     0.991139      0.985164   \n",
       "ALMI               0.944395              0.932459     0.824623      0.890264   \n",
       "AMI                 0.64139              0.652745     0.645387      0.630181   \n",
       "ASMI               0.849539              0.866553     0.823071      0.849554   \n",
       "CLBBB              0.977486              0.986349     0.972556       0.99038   \n",
       "CRBBB              0.994187              0.991337     0.963448      0.988488   \n",
       "EL                 0.819012              0.869271     0.797741      0.858447   \n",
       "ILMI               0.745516              0.797556       0.7237      0.759334   \n",
       "IMI                0.714227              0.685399     0.689993       0.70193   \n",
       "INJAL              0.835031              0.874465     0.877358      0.856101   \n",
       "INJAS              0.898838              0.924629     0.914403      0.877844   \n",
       "INJIL              0.856774              0.898265     0.805204      0.875996   \n",
       "INJIN              0.748945              0.858181       0.6376      0.702063   \n",
       "INJLA              0.975387              0.940928     0.885373      0.975856   \n",
       "IPLMI              0.942347                  0.92      0.90507      0.953427   \n",
       "IPMI                 0.8374              0.915885     0.828602      0.814641   \n",
       "ISCAL              0.911698              0.927538     0.899666      0.903335   \n",
       "ISCAN              0.856338              0.904601     0.884319      0.883944   \n",
       "ISCAS              0.843387              0.821252     0.778773      0.769288   \n",
       "ISCIL              0.784968              0.826746      0.77064      0.803207   \n",
       "ISCIN              0.623035              0.643173     0.619836      0.629781   \n",
       "ISCLA              0.792046              0.795245     0.760726      0.806796   \n",
       "ISC_               0.926782              0.918452     0.897914      0.916939   \n",
       "LMI                0.783191              0.858156     0.628534      0.752222   \n",
       "LNGQT              0.814885              0.808172     0.792393      0.836395   \n",
       "NDT                0.817373              0.832816     0.788476      0.839092   \n",
       "NORM               0.887459              0.882658     0.886405      0.889189   \n",
       "NST_               0.780259              0.825528     0.774259      0.781023   \n",
       "PAC                0.913544               0.71111      0.76963      0.870036   \n",
       "PMI                0.936709              0.994609     0.519925      0.853258   \n",
       "PSVT               0.988118              0.997498     0.994059      0.996873   \n",
       "PVC                0.984375               0.93351     0.943566      0.960474   \n",
       "SBRAD              0.950982              0.961379     0.929804      0.929887   \n",
       "SR                  0.92252              0.859408     0.895632      0.910912   \n",
       "STD_               0.825511              0.847961     0.809211      0.843205   \n",
       "STE_               0.551282              0.598812     0.542996      0.511413   \n",
       "SVTAC                0.9606              0.973108     0.987805      0.988743   \n",
       "TAB_               0.686063              0.810183     0.815462      0.824261   \n",
       "WPW                0.686829              0.820354       0.7692      0.809815   \n",
       "\n",
       "      LeNet+lead1  \n",
       "2AVB     0.761949  \n",
       "3AVB     0.966479  \n",
       "ABQRS     0.62649  \n",
       "AFIB     0.924495  \n",
       "AFLT     0.947033  \n",
       "ALMI     0.894505  \n",
       "AMI       0.68878  \n",
       "ASMI     0.849892  \n",
       "CLBBB    0.988903  \n",
       "CRBBB    0.982998  \n",
       "EL       0.815153  \n",
       "ILMI      0.70708  \n",
       "IMI      0.694948  \n",
       "INJAL    0.804245  \n",
       "INJAS    0.843943  \n",
       "INJIL    0.812471  \n",
       "INJIN    0.712846  \n",
       "INJLA    0.957571  \n",
       "IPLMI    0.787512  \n",
       "IPMI     0.836227  \n",
       "ISCAL    0.882113  \n",
       "ISCAN    0.821596  \n",
       "ISCAS    0.737322  \n",
       "ISCIL    0.827665  \n",
       "ISCIN    0.614723  \n",
       "ISCLA    0.657675  \n",
       "ISC_     0.919546  \n",
       "LMI      0.813995  \n",
       "LNGQT    0.672358  \n",
       "NDT      0.809816  \n",
       "NORM     0.867682  \n",
       "NST_     0.781696  \n",
       "PAC      0.650358  \n",
       "PMI      0.759025  \n",
       "PSVT     0.992495  \n",
       "PVC      0.844193  \n",
       "SBRAD    0.934263  \n",
       "SR       0.819938  \n",
       "STD_     0.843726  \n",
       "STE_      0.51157  \n",
       "SVTAC    0.993277  \n",
       "TAB_     0.897349  \n",
       "WPW      0.692535  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "linear_preds = []\n",
    "\n",
    "for i in range(43):\n",
    "    a =np.array(y_val_preds)[:,:,i].T\n",
    "    model = LinearRegression().fit(a, y_val[:,i])\n",
    "    models += [model]\n",
    "    \n",
    "    linear_preds += [model.predict(np.array(y_test_preds)[:,:,i].T)]\n",
    "\n",
    "linear_preds = np.array(linear_preds).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7914410497714516"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, linear_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_models = []\n",
    "lasso_preds = []\n",
    "\n",
    "for i in range(43):\n",
    "    a =np.array(y_val_preds)[:,:,i].T\n",
    "    model = Lasso(alpha=1e-6).fit(a, y_val[:,i])\n",
    "    lasso_models += [model]\n",
    "    \n",
    "    lasso_preds += [model.predict(np.array(y_test_preds)[:,:,i].T)]\n",
    "\n",
    "lasso_preds = np.array(lasso_preds).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8110906596569444"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, lasso_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_models = []\n",
    "ridge_preds = []\n",
    "\n",
    "for i in range(43):\n",
    "    a =np.array(y_val_preds)[:,:,i].T\n",
    "    model = Ridge().fit(a, y_val[:,i])\n",
    "    ridge_models += [model]\n",
    "    \n",
    "    ridge_preds += [model.predict(np.array(y_test_preds)[:,:,i].T)]\n",
    "\n",
    "ridge_preds = np.array(ridge_preds).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8559274254295787"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, ridge_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 1s 2ms/step - loss: 0.6252\n",
      "68/68 [==============================] - 0s 1ms/step\n",
      "67/67 [==============================] - 1s 1ms/step - loss: 0.6136\n",
      "68/68 [==============================] - 0s 934us/step\n",
      "67/67 [==============================] - 1s 1ms/step - loss: 0.6723\n",
      "68/68 [==============================] - 0s 931us/step\n",
      "67/67 [==============================] - 1s 1ms/step - loss: 0.6380\n",
      "68/68 [==============================] - 0s 743us/step\n",
      "67/67 [==============================] - 1s 1ms/step - loss: 0.6473\n",
      "68/68 [==============================] - 0s 714us/step\n",
      "67/67 [==============================] - 1s 1ms/step - loss: 0.6431\n",
      "68/68 [==============================] - 0s 771us/step\n",
      "67/67 [==============================] - 1s 1ms/step - loss: 0.6678\n",
      "68/68 [==============================] - 0s 932us/step\n",
      "67/67 [==============================] - 1s 1ms/step - loss: 0.6068\n",
      "68/68 [==============================] - 0s 1ms/step\n",
      "67/67 [==============================] - 1s 1ms/step - loss: 0.5974\n",
      "68/68 [==============================] - 0s 924us/step\n",
      "67/67 [==============================] - 1s 1ms/step - loss: 0.6154\n",
      "68/68 [==============================] - 0s 975us/step\n",
      "67/67 [==============================] - 1s 1ms/step - loss: 0.6266\n",
      "68/68 [==============================] - 0s 797us/step\n",
      "67/67 [==============================] - 1s 1ms/step - loss: 0.6013\n",
      "68/68 [==============================] - 0s 793us/step\n",
      "67/67 [==============================] - 1s 978us/step - loss: 0.5957\n",
      "68/68 [==============================] - 0s 856us/step\n",
      "67/67 [==============================] - 1s 1ms/step - loss: 0.6044\n",
      "68/68 [==============================] - 0s 834us/step\n",
      "67/67 [==============================] - 1s 1ms/step - loss: 0.6183\n",
      "68/68 [==============================] - 0s 930us/step\n",
      "67/67 [==============================] - 1s 1ms/step - loss: 0.5940\n",
      "68/68 [==============================] - 0s 906us/step\n",
      "67/67 [==============================] - 1s 1ms/step - loss: 0.5974\n",
      "68/68 [==============================] - 0s 701us/step\n",
      "67/67 [==============================] - 1s 1ms/step - loss: 0.5633\n",
      "68/68 [==============================] - 0s 911us/step\n",
      "67/67 [==============================] - 1s 2ms/step - loss: 0.6220\n",
      "68/68 [==============================] - 0s 1ms/step\n",
      "67/67 [==============================] - 1s 1ms/step - loss: 0.6215\n",
      "68/68 [==============================] - 0s 891us/step\n",
      "67/67 [==============================] - 1s 2ms/step - loss: 0.6152\n",
      "68/68 [==============================] - 0s 923us/step\n",
      "67/67 [==============================] - 1s 1ms/step - loss: 0.5994\n",
      "68/68 [==============================] - 0s 914us/step\n",
      "67/67 [==============================] - 1s 997us/step - loss: 0.5841\n",
      "68/68 [==============================] - 0s 719us/step\n",
      "67/67 [==============================] - 1s 1ms/step - loss: 0.6299\n",
      "68/68 [==============================] - 0s 730us/step\n",
      "67/67 [==============================] - 1s 969us/step - loss: 0.5671\n",
      "68/68 [==============================] - 0s 728us/step\n",
      "67/67 [==============================] - 1s 2ms/step - loss: 0.6067\n",
      "68/68 [==============================] - 0s 1ms/step\n",
      "67/67 [==============================] - 1s 2ms/step - loss: 0.6207\n",
      "68/68 [==============================] - 0s 873us/step\n",
      "67/67 [==============================] - 1s 1ms/step - loss: 0.6630\n",
      "68/68 [==============================] - 0s 910us/step\n",
      "67/67 [==============================] - 1s 1ms/step - loss: 0.6209\n",
      "68/68 [==============================] - 0s 1ms/step\n",
      "67/67 [==============================] - 1s 1ms/step - loss: 0.5602\n",
      "68/68 [==============================] - 0s 939us/step\n",
      "67/67 [==============================] - 1s 1ms/step - loss: 0.6557\n",
      "68/68 [==============================] - 0s 801us/step\n",
      "67/67 [==============================] - 1s 937us/step - loss: 0.6666\n",
      "68/68 [==============================] - 0s 698us/step\n",
      "67/67 [==============================] - 1s 2ms/step - loss: 0.6013\n",
      "68/68 [==============================] - 0s 1ms/step\n",
      "67/67 [==============================] - 1s 1ms/step - loss: 0.6329\n",
      "68/68 [==============================] - 0s 988us/step\n",
      "67/67 [==============================] - 1s 1ms/step - loss: 0.5772\n",
      "68/68 [==============================] - 0s 830us/step\n",
      "67/67 [==============================] - 1s 945us/step - loss: 0.6068\n",
      "68/68 [==============================] - 0s 689us/step\n",
      "67/67 [==============================] - 1s 1ms/step - loss: 0.6009\n",
      "68/68 [==============================] - 0s 734us/step\n",
      "67/67 [==============================] - 1s 947us/step - loss: 0.7038\n",
      "68/68 [==============================] - 0s 643us/step\n",
      "67/67 [==============================] - 1s 933us/step - loss: 0.6225\n",
      "68/68 [==============================] - 0s 650us/step\n",
      "67/67 [==============================] - 1s 931us/step - loss: 0.6479\n",
      "68/68 [==============================] - 0s 597us/step\n",
      "67/67 [==============================] - 1s 919us/step - loss: 0.6445\n",
      "68/68 [==============================] - 0s 967us/step\n",
      "67/67 [==============================] - 1s 855us/step - loss: 0.6110\n",
      "68/68 [==============================] - 0s 864us/step\n",
      "67/67 [==============================] - 1s 816us/step - loss: 0.6260\n",
      "68/68 [==============================] - 0s 733us/step\n"
     ]
    }
   ],
   "source": [
    "nn_models = []\n",
    "nn_preds = []\n",
    "\n",
    "for i in range(43):\n",
    "    a =np.array(y_val_preds)[:,:,i].T\n",
    "    model = Sequential()\n",
    "    # model.add(Dense(a.shape[1], activation='relu'))\n",
    "    model.add(Dense(16, activation='relu', input_shape=(a.shape[1],)))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    model.fit(a, np.array([y_val[:,i]]).T)\n",
    "    nn_models += [model]\n",
    "    \n",
    "    nn_preds += [model.predict(np.array(y_test_preds)[:,:,i].T)]\n",
    "\n",
    "nn_preds = np.array(nn_preds).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29142032286469993"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, nn_preds[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
