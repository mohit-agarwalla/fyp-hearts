{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../..\")\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputfolder = os.getcwd() + '/output/'\n",
    "datafolder = os.getcwd() + '/datasets/PTB-XL/'\n",
    "sampling_rate = 100\n",
    "task = 'priority'\n",
    "experiment_name = 'exp4'\n",
    "\n",
    "data, raw_labels = utils.load_dataset(datafolder, sampling_rate=sampling_rate)\n",
    "labels = utils.compute_label_aggregations(raw_labels, datafolder, task)\n",
    "data, labels, Y, _ = utils.select_data(data, labels, task, 0, outputfolder+experiment_name+'/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This experiment has 43 classes\n"
     ]
    }
   ],
   "source": [
    "X_test = data[labels.strat_fold == 10]\n",
    "y_test = Y[labels.strat_fold == 10]\n",
    "\n",
    "X_val = data[labels.strat_fold == 9]\n",
    "y_val = Y[labels.strat_fold == 9]\n",
    "\n",
    "X_train = data[labels.strat_fold <= 8]\n",
    "y_train = Y[labels.strat_fold <= 8]\n",
    "\n",
    "n_classes = y_train.shape[1]\n",
    "\n",
    "print(f\"This experiment has {n_classes} classes\")\n",
    "\n",
    "X_train = X_train[:,:,0]\n",
    "X_test = X_test[:,:,0]\n",
    "X_val = X_val[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, GRU, TimeDistributed, Bidirectional, LeakyReLU\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten,  Input, Reshape\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D, GlobalAveragePooling1D,MaxPool1D,AveragePooling1D\n",
    "from tensorflow.keras import initializers, regularizers, constraints\n",
    "from tensorflow.keras.layers import Layer\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import BatchNormalization, ReLU, MaxPooling1D, LSTM\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 1000, 1)]         0         \n",
      "                                                                 \n",
      " conv1d_21 (Conv1D)          (None, 1000, 64)          384       \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 1000, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_20 (ReLU)             (None, 1000, 64)          0         \n",
      "                                                                 \n",
      " max_pooling1d_20 (MaxPoolin  (None, 250, 64)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_22 (Conv1D)          (None, 250, 128)          41088     \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 250, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_21 (ReLU)             (None, 250, 128)          0         \n",
      "                                                                 \n",
      " max_pooling1d_21 (MaxPoolin  (None, 62, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_23 (Conv1D)          (None, 62, 256)           164096    \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 62, 256)          1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_22 (ReLU)             (None, 62, 256)           0         \n",
      "                                                                 \n",
      " max_pooling1d_22 (MaxPoolin  (None, 15, 256)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 15, 128)           197120    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 15, 128)           0         \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 15, 64)            49408     \n",
      "                                                                 \n",
      " global_average_pooling1d_1   (None, 64)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 43)                5547      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 467,755\n",
      "Trainable params: 466,859\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(1000,1))\n",
    "x = Conv1D(filters=64, kernel_size=5, strides=1, padding='same')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=4, strides=4)(x)\n",
    "\n",
    "x = Conv1D(filters=128, kernel_size=5, strides=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=4, strides=4)(x)\n",
    "\n",
    "x = Conv1D(filters=256, kernel_size=5, strides=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=4, strides=4)(x)\n",
    "# x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "x = LSTM(128, return_sequences=True)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = LSTM(64, return_sequences=True)(x)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "outputs = Dense(43, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy',threshold=0.5),\n",
    "            tf.keras.metrics.Recall(name='recall'),\n",
    "            tf.keras.metrics.AUC(num_thresholds=200,\n",
    "                                curve=\"ROC\",\n",
    "                                summation_method='interpolation',\n",
    "                                name=\"AUC\",\n",
    "                                multi_label=True,\n",
    "                                label_weights=None)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "534/534 [==============================] - 93s 157ms/step - loss: 0.1262 - accuracy: 0.9600 - recall: 0.4203 - AUC: 0.5418 - val_loss: 0.1125 - val_accuracy: 0.9629 - val_recall: 0.3947 - val_AUC: 0.6376\n",
      "Epoch 2/30\n",
      "534/534 [==============================] - 77s 144ms/step - loss: 0.1107 - accuracy: 0.9654 - recall: 0.4906 - AUC: 0.6235 - val_loss: 0.1042 - val_accuracy: 0.9666 - val_recall: 0.5213 - val_AUC: 0.6723\n",
      "Epoch 3/30\n",
      "534/534 [==============================] - 82s 154ms/step - loss: 0.1080 - accuracy: 0.9657 - recall: 0.4992 - AUC: 0.6512 - val_loss: 0.1061 - val_accuracy: 0.9666 - val_recall: 0.5178 - val_AUC: 0.6537\n",
      "Epoch 4/30\n",
      "534/534 [==============================] - 80s 149ms/step - loss: 0.1075 - accuracy: 0.9659 - recall: 0.5015 - AUC: 0.6538 - val_loss: 0.1078 - val_accuracy: 0.9654 - val_recall: 0.4589 - val_AUC: 0.6430\n",
      "Epoch 5/30\n",
      "534/534 [==============================] - 87s 163ms/step - loss: 0.1067 - accuracy: 0.9660 - recall: 0.5051 - AUC: 0.6576 - val_loss: 0.1053 - val_accuracy: 0.9664 - val_recall: 0.4946 - val_AUC: 0.6663\n",
      "Epoch 6/30\n",
      "534/534 [==============================] - 117s 219ms/step - loss: 0.1062 - accuracy: 0.9659 - recall: 0.4985 - AUC: 0.6541 - val_loss: 0.1055 - val_accuracy: 0.9667 - val_recall: 0.5159 - val_AUC: 0.6598\n",
      "Epoch 7/30\n",
      "534/534 [==============================] - 145s 272ms/step - loss: 0.1056 - accuracy: 0.9660 - recall: 0.5054 - AUC: 0.6571 - val_loss: 0.1082 - val_accuracy: 0.9665 - val_recall: 0.4981 - val_AUC: 0.6186\n",
      "Epoch 8/30\n",
      "534/534 [==============================] - 183s 343ms/step - loss: 0.1049 - accuracy: 0.9662 - recall: 0.5033 - AUC: 0.6686 - val_loss: 0.1029 - val_accuracy: 0.9668 - val_recall: 0.5167 - val_AUC: 0.6730\n",
      "Epoch 9/30\n",
      "534/534 [==============================] - 154s 289ms/step - loss: 0.1039 - accuracy: 0.9661 - recall: 0.5032 - AUC: 0.6795 - val_loss: 0.1071 - val_accuracy: 0.9666 - val_recall: 0.4964 - val_AUC: 0.6446\n",
      "Epoch 10/30\n",
      "534/534 [==============================] - 1287s 2s/step - loss: 0.1044 - accuracy: 0.9661 - recall: 0.4975 - AUC: 0.6730 - val_loss: 0.1044 - val_accuracy: 0.9668 - val_recall: 0.5305 - val_AUC: 0.6766\n",
      "Epoch 11/30\n",
      "534/534 [==============================] - 106s 198ms/step - loss: 0.1031 - accuracy: 0.9666 - recall: 0.5017 - AUC: 0.6806 - val_loss: 0.1054 - val_accuracy: 0.9660 - val_recall: 0.4772 - val_AUC: 0.6614\n",
      "Epoch 12/30\n",
      "534/534 [==============================] - 106s 199ms/step - loss: 0.1024 - accuracy: 0.9668 - recall: 0.4981 - AUC: 0.6830 - val_loss: 0.1047 - val_accuracy: 0.9669 - val_recall: 0.4645 - val_AUC: 0.6560\n",
      "Epoch 13/30\n",
      "534/534 [==============================] - 108s 202ms/step - loss: 0.1012 - accuracy: 0.9669 - recall: 0.4958 - AUC: 0.6907 - val_loss: 0.1033 - val_accuracy: 0.9669 - val_recall: 0.4950 - val_AUC: 0.6873\n",
      "Epoch 14/30\n",
      "534/534 [==============================] - 150s 281ms/step - loss: 0.1018 - accuracy: 0.9667 - recall: 0.4976 - AUC: 0.6888 - val_loss: 0.1054 - val_accuracy: 0.9663 - val_recall: 0.4868 - val_AUC: 0.6506\n",
      "Epoch 15/30\n",
      "534/534 [==============================] - 164s 307ms/step - loss: 0.1011 - accuracy: 0.9673 - recall: 0.5068 - AUC: 0.6975 - val_loss: 0.1083 - val_accuracy: 0.9642 - val_recall: 0.4162 - val_AUC: 0.6734\n",
      "Epoch 16/30\n",
      "534/534 [==============================] - 198s 371ms/step - loss: 0.1003 - accuracy: 0.9672 - recall: 0.4988 - AUC: 0.7027 - val_loss: 0.1019 - val_accuracy: 0.9672 - val_recall: 0.5253 - val_AUC: 0.6798\n",
      "Epoch 17/30\n",
      "534/534 [==============================] - 187s 351ms/step - loss: 0.1000 - accuracy: 0.9675 - recall: 0.4994 - AUC: 0.7012 - val_loss: 0.1096 - val_accuracy: 0.9626 - val_recall: 0.3423 - val_AUC: 0.6842\n",
      "Epoch 18/30\n",
      "534/534 [==============================] - 173s 324ms/step - loss: 0.0994 - accuracy: 0.9674 - recall: 0.4985 - AUC: 0.7100 - val_loss: 0.1063 - val_accuracy: 0.9657 - val_recall: 0.4263 - val_AUC: 0.6509\n",
      "Epoch 19/30\n",
      "534/534 [==============================] - 166s 310ms/step - loss: 0.0994 - accuracy: 0.9676 - recall: 0.5010 - AUC: 0.7041 - val_loss: 0.1039 - val_accuracy: 0.9654 - val_recall: 0.3931 - val_AUC: 0.7108\n",
      "Epoch 20/30\n",
      "534/534 [==============================] - 159s 298ms/step - loss: 0.0991 - accuracy: 0.9676 - recall: 0.5022 - AUC: 0.7102 - val_loss: 0.1018 - val_accuracy: 0.9675 - val_recall: 0.5021 - val_AUC: 0.6912\n",
      "Epoch 21/30\n",
      "534/534 [==============================] - 152s 285ms/step - loss: 0.0987 - accuracy: 0.9677 - recall: 0.5061 - AUC: 0.7096 - val_loss: 0.1007 - val_accuracy: 0.9677 - val_recall: 0.5280 - val_AUC: 0.6831\n",
      "Epoch 22/30\n",
      "534/534 [==============================] - 152s 286ms/step - loss: 0.0987 - accuracy: 0.9677 - recall: 0.5039 - AUC: 0.7173 - val_loss: 0.0992 - val_accuracy: 0.9682 - val_recall: 0.4975 - val_AUC: 0.7147\n",
      "Epoch 23/30\n",
      "534/534 [==============================] - 152s 285ms/step - loss: 0.0984 - accuracy: 0.9677 - recall: 0.5059 - AUC: 0.7257 - val_loss: 0.1003 - val_accuracy: 0.9676 - val_recall: 0.4793 - val_AUC: 0.7137\n",
      "Epoch 24/30\n",
      "534/534 [==============================] - 156s 292ms/step - loss: 0.0986 - accuracy: 0.9675 - recall: 0.5040 - AUC: 0.7142 - val_loss: 0.1003 - val_accuracy: 0.9675 - val_recall: 0.4451 - val_AUC: 0.7066\n",
      "Epoch 25/30\n",
      "534/534 [==============================] - 168s 314ms/step - loss: 0.0990 - accuracy: 0.9674 - recall: 0.5018 - AUC: 0.7042 - val_loss: 0.1051 - val_accuracy: 0.9658 - val_recall: 0.4683 - val_AUC: 0.6808\n",
      "Epoch 26/30\n",
      "534/534 [==============================] - 180s 337ms/step - loss: 0.0987 - accuracy: 0.9674 - recall: 0.5006 - AUC: 0.7096 - val_loss: 0.1008 - val_accuracy: 0.9680 - val_recall: 0.5075 - val_AUC: 0.7109\n",
      "Epoch 27/30\n",
      "534/534 [==============================] - 178s 333ms/step - loss: 0.0980 - accuracy: 0.9677 - recall: 0.5085 - AUC: 0.7184 - val_loss: 0.1140 - val_accuracy: 0.9640 - val_recall: 0.3659 - val_AUC: 0.6921\n",
      "Epoch 28/30\n",
      "534/534 [==============================] - 191s 358ms/step - loss: 0.0979 - accuracy: 0.9677 - recall: 0.5044 - AUC: 0.7189 - val_loss: 0.1000 - val_accuracy: 0.9668 - val_recall: 0.4499 - val_AUC: 0.7185\n",
      "Epoch 29/30\n",
      "534/534 [==============================] - 123s 230ms/step - loss: 0.0989 - accuracy: 0.9676 - recall: 0.5068 - AUC: 0.7188 - val_loss: 0.1020 - val_accuracy: 0.9672 - val_recall: 0.4576 - val_AUC: 0.7043\n",
      "Epoch 30/30\n",
      "534/534 [==============================] - 83s 155ms/step - loss: 0.0988 - accuracy: 0.9673 - recall: 0.5030 - AUC: 0.7088 - val_loss: 0.1061 - val_accuracy: 0.9626 - val_recall: 0.3532 - val_AUC: 0.6883\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1000, 1)]         0         \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 1000, 64)          384       \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 1000, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_5 (ReLU)              (None, 1000, 64)          0         \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 250, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 250, 128)          41088     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 250, 128)         512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_6 (ReLU)              (None, 250, 128)          0         \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 62, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 62, 256)           164096    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 62, 256)          1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_7 (ReLU)              (None, 62, 256)           0         \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 15, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 15, 128)           197120    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 15, 128)           0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 15, 64)            49408     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 15, 64)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 15, 128)           8320      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 15, 128)           0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 15, 43)            5547      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 467,755\n",
      "Trainable params: 466,859\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "# plot_model(model)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 5s 42ms/step\n",
      "0.7470347031178826\n",
      "68/68 [==============================] - 4s 55ms/step - loss: 0.1060 - accuracy: 0.9624 - recall: 0.3508 - AUC: 0.6794\n",
      "[0.10596800595521927, 0.9624312520027161, 0.35084426403045654, 0.6794029474258423]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "print(roc_auc_score(y_test,preds))\n",
    "auc = model.evaluate(X_test, y_test)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
